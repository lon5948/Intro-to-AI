{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMUBeLb0GPXB0Rnyf9P6ER4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qzyxexr1c5DV","executionInfo":{"status":"ok","timestamp":1649577084584,"user_tz":-480,"elapsed":18004,"user":{"displayName":"李旻融","userId":"04935932674488625365"}},"outputId":"3db0d7b0-f4c0-4122-c529-7eba97f737eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!cp -r /content/gdrive/MyDrive/HW2/* ."]},{"cell_type":"code","source":["!chmod 755 /content/gdrive/MyDrive/HW2/run.sh\n","!/content/gdrive/MyDrive/HW2/run.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4wt1IP8RdRNT","executionInfo":{"status":"ok","timestamp":1649600398118,"user_tz":-480,"elapsed":680,"user":{"displayName":"李旻融","userId":"04935932674488625365"}},"outputId":"91318ecb-3d53-40b6-8e27-d774d994dd9a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["chmod: cannot access '/content/gdrive/MyDrive/HW2/run.sh': Transport endpoint is not connected\n","/bin/bash: /content/gdrive/MyDrive/HW2/run.sh: Transport endpoint is not connected\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from sklearn.metrics import precision_recall_fscore_support\n","from torch.utils.data import Dataset\n","from tqdm import tqdm\n","#!pip install transformers\n","from transformers import AutoModel, AutoTokenizer\n","\n","\n","class MovieDataset(Dataset):\n","    def __init__(self, df):\n","        super().__init__()\n","        self.data = {}\n","        for idx, row in df.iterrows():\n","            self.data[idx] = (row['review'], row['sentiment'])\n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        review, sentiment = self.data[idx]\n","        return (review, torch.tensor(sentiment))\n","\n","\n","class BERT_IMDB(nn.Module):\n","    '''\n","    Fine-tuning DistillBert with two MLPs.\n","    '''\n","    def __init__(self, pretrained_type):\n","        super().__init__()\n","\n","        num_labels = 2\n","        self.pretrained_model = AutoModel.from_pretrained(pretrained_type, num_labels=num_labels)\n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(768, 512),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, num_labels)\n","        )\n","\n","    def forward(self, **pretrained_text):\n","        outputs = self.pretrained_model(**pretrained_text).last_hidden_state\n","        pretrained_output = outputs[:, 0, :]\n","        logits = self.classifier(pretrained_output)\n","        \n","        return logits\n","\n","\n","class BERT:\n","    def __init__(self, pretrained_type, config):\n","        self.config = config\n","        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_type)\n","        self.model = BERT_IMDB(pretrained_type).to(config['device'])\n","\n","    def train_sentiment(self, train_dataloader, test_dataloader):\n","        device = self.config['device']\n","        ce_loss = nn.CrossEntropyLoss().to(device)\n","        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.config['lr'])\n","\n","        for epoch in tqdm(range(self.config['epochs'])):\n","            # training stage\n","            self.model.train()\n","            total_loss = 0\n","            for data in tqdm(train_dataloader):\n","                optimizer.zero_grad()\n","                text, label = list(data[0]), data[1].to(device)\n","                input_text = self.tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n","                outputs = self.model(**input_text)\n","\n","                loss = ce_loss(outputs, label)\n","                total_loss += loss.item()\n","                loss.backward()\n","                optimizer.step()\n","\n","            # evaluating stage\n","            self.model.eval()\n","            pred = []\n","            labels = []\n","            for data in test_dataloader:\n","                text, label = list(data[0]), data[1].to(device)\n","                input_text = self.tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n","                with torch.no_grad():\n","                    outputs = self.model(**input_text)\n","                pred.append(torch.argmax(outputs, dim=-1).cpu().numpy())\n","                labels.append(label.cpu().numpy())\n","\n","            precision, recall, f1, support = precision_recall_fscore_support(labels, pred, average='macro', zero_division=1)\n","            precision = round(precision, 4)\n","            recall = round(recall, 4)\n","            f1 = round(f1, 4)\n","            avg_loss = round(total_loss/len(train_dataloader), 4)\n","            print(f\"Epoch: {epoch}, F1 score: {f1}, Precision: {precision}, Recall: {recall}, Loss: {avg_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sOP1mzC7eyAE","executionInfo":{"status":"ok","timestamp":1649577823709,"user_tz":-480,"elapsed":7116,"user":{"displayName":"李旻融","userId":"04935932674488625365"}},"outputId":"f85f848a-d7c0-4005-cb8d-4fe82f04a860"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}]}]}